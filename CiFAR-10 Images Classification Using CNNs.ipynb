{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ec3e7d",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# CIFAR-10 Image Classification Using CNN\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74591432",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT\n",
    "CIFAR-10 is a dataset that consists of several images divided into the following 10 classes:\n",
    "\n",
    "- Airplanes\n",
    "- Cars\n",
    "- Birds\n",
    "- Cats\n",
    "- Deer\n",
    "- Dogs\n",
    "- Frogs\n",
    "- Horses\n",
    "- Ships\n",
    "- Trucks\n",
    "\n",
    "The dataset stands for the Canadian Institute For Advanced Research (CIFAR)\n",
    "\n",
    "CIFAR-10 is widely used for machine learning and computer vision applications.\n",
    "\n",
    "The dataset consists of 60,000 32x32 color images and 6,000 images of each class.\n",
    "\n",
    "Images have low resolution (32x32).\n",
    "\n",
    "Data Source: https://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23134e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, models, layers, optimizers\n",
    "from tensorflow.keras.utils import to_categorical, array_to_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8571d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d94a4bf",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 1: LOAD CIFAR-10 DATA\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82c5a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train_raw), (X_test, y_test_raw) = datasets.cifar10.load_data()\n",
    "\n",
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
    "               \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "print(\"Train images:\", X_train.shape)\n",
    "print(\"Test images:\", X_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41360460",
   "metadata": {},
   "source": [
    "\n",
    "# ============================================================\n",
    "# STEP 2: VISUALIZE SAMPLE IMAGES\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a2160a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(X_train[100])\n",
    "plt.title(class_names[y_train_raw[100][0]])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Grid of images\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "axes = axes.ravel()\n",
    "for i in range(16):\n",
    "    idx = np.random.randint(0, X_train.shape[0])\n",
    "    axes[i].imshow(X_train[idx])\n",
    "    axes[i].set_title(class_names[y_train_raw[idx][0]])\n",
    "    axes[i].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea3eee",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 3: DATA PREPARATION (NORMALIZATION + ONE-HOT ENCODING)\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel intensities\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_test  = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# One-hot encoding of labels\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train_raw, num_classes)\n",
    "y_test  = to_categorical(y_test_raw, num_classes)\n",
    "\n",
    "input_shape = X_train.shape[1:]\n",
    "print(\"Input shape:\", input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5853ad",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 4: BUILD CNN MODEL\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3281cebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = models.Sequential([\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=input_shape),\n",
    "    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    layers.Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Dropout(0.4),\n",
    "\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(1024, activation=\"relu\"),\n",
    "    layers.Dense(1024, activation=\"relu\"),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "cnn_model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=optimizers.RMSprop(learning_rate=0.001),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f70dcd",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 5: TRAIN MODEL\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefdad56",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = cnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_split=0.1,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8ae211",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 6: EVALUATE MODEL + CONFUSION MATRIX\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6b82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy (Baseline): {test_acc:.4f}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_prob = cnn_model.predict(X_test)\n",
    "y_pred_class = np.argmax(y_pred_prob, axis=1)\n",
    "y_true_class = y_test_raw.flatten()\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_class, y_pred_class)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=False, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix - Baseline Model\")\n",
    "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true_class, y_pred_class, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7df800c",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 7: SAVE BASELINE MODEL\n",
    "# ============================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e1353",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"saved_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "baseline_path = os.path.join(save_dir, \"cnn_cifar10_baseline.keras\")\n",
    "cnn_model.save(baseline_path)\n",
    "\n",
    "print(\"Baseline model saved to:\", baseline_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b84a42f",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 8: DATA AUGMENTATION & IMPROVED TRAINING\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "datagen.fit(X_train)\n",
    "\n",
    "# Visualize augmented images\n",
    "sample = X_train[:8]\n",
    "fig = plt.figure(figsize=(12, 2))\n",
    "\n",
    "for batch in datagen.flow(sample, batch_size=8):\n",
    "    for i in range(8):\n",
    "        ax = fig.add_subplot(1, 8, i + 1)\n",
    "        ax.imshow(array_to_img(batch[i]))\n",
    "        ax.axis(\"off\")\n",
    "    plt.suptitle(\"Example Augmented Images\")\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "# Train with augmentation\n",
    "history_aug = cnn_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    epochs=5,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n",
    "\n",
    "# Evaluate augmented model\n",
    "loss_aug, acc_aug = cnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy (With Augmentation): {acc_aug:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182633e7",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# STEP 9: SAVE AUGMENTED MODEL\n",
    "# ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4197b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_path = os.path.join(save_dir, \"cnn_cifar10_augmented.keras\")\n",
    "cnn_model.save(aug_path)\n",
    "\n",
    "print(\"Augmented model saved to:\", aug_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375a9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa4a538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af00b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b377748b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb565bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b86440",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790343d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d88b5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704dd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7b5910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e70b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3baee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
